<h3>A Dynamic Data Analytics Workflow</h3>
<p>Due to the variety and increasing complexity of Data Analysis applications, and the types of users ranging from skilled programmers to novice data scientists, there is a need for scalable programming models with different levels of abstractions and design formalisms. </p>

<p>The programming models should adapt to user needs by allowing, </p>

<ol type="i">
  <li>ease in defining data analysis applications</li>
  <li>effectiveness in the analysis of large datasets </li>
  <li>and efficiency of executing applications on large scale architectures.</li>
</ol>

<p>From the data analytics programming models available, workflows have been identified as an effective paradigm to adequately meet these requirements. </p>
<p>Data Analytics consists of applying a sequence of steps in order to extract knowledge. Take a look at the diagram below for the generally accepted static data analytics workflow. Such a workflow fits well with the workflow model weâ€™re trying to enhance through SciFlow. </p>

<img class="media-object" src="../../../assets/png/staticWF.png" width="600">

<p>Our project seeks applies the SciFlow framework, in a Data Analytics context, in order to predict social unrest using the GDELT (Global Database of Events, Language and Tone) dataset. Additional data is captured from the ACLED (Armed Conflict Location & Event Data Project) dataset.</p>
<p>Accordingly, we construct the below data analytics workflow, which include the following features;</p>

<ul>
  <li>Multiple workflow components</li>
  <li>Interacting workflow modules</li>
  <li>Reusable and parallelizable modules</li>
  <li>Complex workflow constructs, such as intersections and forks</li>
  <li>Dynamic decision making</li>

</ul>
<br>

<ngx-image-zoom
    [thumbImage]=myThumbnail
    [fullImage]=myFullresImage
    [magnification]="3"
    [enableScrollZoom]="true"
    [enableLens]="true"
    [lensWidth]="200"
    [lensHeight] = "100"
></ngx-image-zoom>

<!--<img class="media-object" src="../../../assets/workflow.png" width="650">-->
<br>
<p>The workflow can be broken down to several components;</p>

<ul>
  <li><b>gdeltFileSelection</b> : A GDELT specific component which includes modules for file selection and integration, from the daily files provided by the GDELT database. </li>
  <li><b>Selection</b> : Modules for selection of necessary rows and columns for further processing.</li>
  <li><b>Cleaning</b> : Handles missing values, duplicate rows, unique columns etc. </li>
  <li><b>Transformation</b> : Transformation modules such as normalize, standardize, encode, rescale, binarize etc.</li>
  <li><b>integrateLabel</b> : An ACLED specific component, to append a label (indicating whether unrest actually arose or not) to the GDELT dataset.</li>
  <li><b>Mining</b> : For implementations of all mining algorithms (K-Means, SVM, Random Forest etc.) and related knowledge presentation. </li>
</ul>

<p>For further information, checkout the code for this case study at <a href="https://github.com/SciFlow-FYP/DataAnalyticsWorkflow">https://github.com/SciFlow-FYP/DataAnalyticsWorkflow</a>.</p>
<p>We welcome contributions! You can contribute to this project using the above link.</p>
