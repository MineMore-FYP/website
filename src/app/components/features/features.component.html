
<div class="col-md-1"></div>
  <div class="col-md-10">
      <div class="panel panel-default">

          <div class="panel-body">
            <br>

            <h3>Reusability</h3>
            <p>With SciFlow, the modules you create are fully reusable. They can easily be plugged to any workflow you create thereafter. Creating such modules are easy as well! They are simply python functions. </p>
            <br>
            <h3>Spawn many Instances</h3>
            <p>You can now spawn multiple instances of the same module in parallel, with very little trouble! With a simple ‘for’ loop, Parsl would generate and execute many instances of a single module. </p>
            <br>
            <h3>Dynamism</h3>
            <p>The go control thread would make run-time decisions for you!  The Go thread would make a decision regarding the most appropriate path to take and redirect along this path.</p>

            <p>This allows the framework to perform hyper-parameter optimization and meta-heuristics. No manual intervention is required. The framework would select the best parameter/solution set and forward it to the next stage of the workflow.</p>
            <br>
            <h3>Flexibility</h3>
            <p>Each module (event) is executed once the event is ready. Channels provide the ability for the workflow to be event-driven.</p>
            <p>A traditional data analytics approach, would be to execute a sequence of data analytics modules step-by-step. The framework provides automation of this process and channels allow the control thread to make a decision at runtime and redirect the workflow as appropriate.</p>
            <br>
            <h3>Composability</h3>
            <p>The framework provides a very generic control thread. With minor changes, the user could easily construct any workflow, write a user script with his parameters and change cluster configuration as necessary.</p>

            <p>You just need to follow the instructions given!</p>
            <br>
            <h3>Predefined workflow instructions</h3>
            <p>You can setup the control thread beforehand and the script would run with no intervention required. This is beneficial if the data mining process takes a long time to complete.</p>
            <br>
            <h3>Easy Configuration on HPC</h3>
            <p>With the use of Parsl, you could easily adjust machine(threads/cores) or cluster configurations, by simply loading a pre-written configuration file. You’re relieved from the usual MPI burden associated with working on a cluster. </p>
            <p>Parsl provides numerous other execution environments as well, such as, Amazon Web Services, Google Cloud, Slurm based cluster or supercomputer, Torque/PBS based cluster or supercomputer, Kubernetes cluster etc. The framework can be easily configured for any of these environments!</p>
            <br>
            <h3>Map-reduce like approach</h3>
            <p>The framework’s approach maps to a manual map-reduce-like approach, thereby, providing all the benefits of map reduce as well. This behaviour is mimicked by parsl.  </p>

            <p>The framework would divide a task among threads/cores/cluster machines, perform the computation and finally combine the results. </p>


          </div>
      </div>
  </div>

<div class="col-md-1"></div>
